{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f915ebef",
   "metadata": {},
   "source": [
    "# YOLOv8 Exercise\n",
    "\n",
    "The contents of this jupyter notebook is my exploration on YOLOv8, following the [YOLOv8 Tutorial](https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb) notebook.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baea94f9",
   "metadata": {},
   "source": [
    "# 0. Preparation\n",
    "\n",
    "## 0-1. Install `ultralytics`\n",
    "\n",
    "First, install `ultralytics` with pip.  \n",
    "Then check if `ultralytics` was correctly installed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c4fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ultralytics # install ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks() # check if ultralytics is installed correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f078a8",
   "metadata": {},
   "source": [
    "## 0-2. Prepare images\n",
    "\n",
    "Since my goal is to detect human faces, I prepared some free images containing human faces.  \n",
    "The format of the images are fixed as `jpeg`, and are named like `human_x.jpeg` where `x` is the image index(no special meaning in the index).   \n",
    "\n",
    "The images are downloaded from [here](https://www.pexels.com/search/human%20face/).  \n",
    "They are saved right under `img` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51382a03",
   "metadata": {},
   "source": [
    "# 1. Use a pretrained model\n",
    "\n",
    "Mainly two ways are provided to use YOLOv8.\n",
    "\n",
    "1. A command line tool\n",
    "2. A python API\n",
    "\n",
    "I chose to use the python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4add06f",
   "metadata": {},
   "source": [
    "## 1-1. Detect a person\n",
    "\n",
    "Using the pretrained detection model \"yolov8n.pt\", detection of a person was done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11dfd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# load a pretrained model (recommended for training)\n",
    "model = YOLO(\"yolov8n.pt\") \n",
    "\n",
    "# results = model(\"img/human_1.jpeg\")\n",
    "results = model.predict(source=\"img/human_1.jpeg\", show=True) # same as above\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795360b7",
   "metadata": {},
   "source": [
    "## 1-2. Detect face\n",
    "\n",
    "I downloaded the pretrained face detection model(\"yolov8n-face.pt\") from [here](https://github.com/akanametov/yolov8-face?tab=readme-ov-file)  \n",
    "Using the model, I got the (x,y,width,height) of the face ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853b4bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a pretrained model (recommended for training)\n",
    "model = YOLO(\"./yolov8n-face.pt\") \n",
    "\n",
    "# results = model(\"img/human_1.jpeg\")\n",
    "results = model.predict(source=\"img/human_2.jpeg\", show=True, save=True)\n",
    "# results = model.predict(source=\"img/chara_1.png\", show=True, save=True)\n",
    "\n",
    "\n",
    "# print(results)\n",
    "# print(results[0].boxes[0].xyxy)\n",
    "# print(results[0].boxes[0].xywh)\n",
    "human_box_xywh = results[0].boxes[0].xywh[0]\n",
    "print(\"x: \", results[0].boxes[0].xywh[0][0])\n",
    "print(\"y: \", results[0].boxes[0].xywh[0][1])\n",
    "print(\"w: \", results[0].boxes[0].xywh[0][2])\n",
    "print(\"h: \", results[0].boxes[0].xywh[0][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddd9fb9",
   "metadata": {},
   "source": [
    "## 1-3. Detect animation character face\n",
    "\n",
    "It is a bit questionable whether detecting a character's face with the same model is approperiate.  \n",
    "At the same time, using the same model can be a good approach because detection standard is the same.  \n",
    "For example if the sizes of two different face ROIs are simililer, the face sizes could be thought as similier(just my assumption).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0872b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a pretrained model (recommended for training)\n",
    "model = YOLO(\"./yolov8n-face.pt\") \n",
    "\n",
    "# results = model(\"img/human_1.jpeg\")\n",
    "# results = model.predict(source=\"img/human_2.jpeg\", show=True, save=True)\n",
    "results = model.predict(source=\"img/chara_1.png\", show=True)\n",
    "\n",
    "\n",
    "# print(results)\n",
    "# print(results[0].boxes[0].xyxy)\n",
    "# print(results[0].boxes[0].xywh)\n",
    "chara_box_xywh = results[0].boxes[0].xywh[0]\n",
    "print(\"x: \", results[0].boxes[0].xywh[0][0])\n",
    "print(\"y: \", results[0].boxes[0].xywh[0][1])\n",
    "print(\"w: \", results[0].boxes[0].xywh[0][2])\n",
    "print(\"h: \", results[0].boxes[0].xywh[0][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7907c1da",
   "metadata": {},
   "source": [
    "# 2. Placing an image of a character according to the face detection\n",
    "\n",
    "The final goal of this notebook is to resize a prepared image of a character and placing it alongside the detected face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e789b4ed",
   "metadata": {},
   "source": [
    "## 2-1. Adjusting image size.\n",
    "\n",
    "By comparing `human_box_xywh` and `chara_box_xywh`, resizing the character image to make its size similer to the human might be possible.  \n",
    "I tried three types of resizing.  \n",
    "\n",
    "1. adjust to width\n",
    "2. adjust to height\n",
    "3. adjust to area(width * height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19735e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# load a pretrained model (recommended for training)\n",
    "model = YOLO(\"./yolov8n-face.pt\")\n",
    "\n",
    "results = model.predict(source=\"img/human_2.jpeg\")\n",
    "human_box_xywh = results[0].boxes[0].xywh[0]\n",
    "\n",
    "results = model.predict(source=\"img/chara_1.png\")\n",
    "chara_box_xywh = results[0].boxes[0].xywh[0]\n",
    "\n",
    "\"\"\"\n",
    "Human image size is fixed.(Only character image size is adjusted to human image size.)\n",
    "\"\"\"\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "chara_image = Image.open(\"img/chara_1.png\")\n",
    "\n",
    "# 1. adjust to width\n",
    "new_width = int(chara_image.width * human_box_xywh[2] / chara_box_xywh[2])\n",
    "new_height = int(chara_image.height * human_box_xywh[2] / chara_box_xywh[2])\n",
    "resized_chara_image = chara_image.resize((new_width, new_height))\n",
    "resized_chara_image.save(\"resized_img/resized_by_width_chara_1.png\")\n",
    "\n",
    "# # 2. adjust to height\n",
    "new_width = int(chara_image.width * human_box_xywh[3] / chara_box_xywh[3])\n",
    "new_height = int(chara_image.height * human_box_xywh[3] / chara_box_xywh[3])\n",
    "resized_chara_image = chara_image.resize((new_width, new_height))\n",
    "resized_chara_image.save(\"resized_img/resized_by_height_chara_1.png\")\n",
    "\n",
    "# # 3. adjust to area(width * height)\n",
    "\n",
    "new_width = int(chara_image.width * math.sqrt((human_box_xywh[2]*human_box_xywh[3]) / (chara_box_xywh[2]*chara_box_xywh[3])))\n",
    "new_height = int(chara_image.height * math.sqrt((human_box_xywh[2]*human_box_xywh[3]) / (chara_box_xywh[2]*chara_box_xywh[3])))\n",
    "resized_chara_image = chara_image.resize((new_width, new_height))\n",
    "resized_chara_image.save(\"resized_img/resized_by_area_chara_1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06872e9f",
   "metadata": {},
   "source": [
    "## 2-2. Draw(?) the character image over ther human image\n",
    "\n",
    "Just tried for the case of \"1. adjust to width\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb6048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "\n",
    "sub_img_names = [\n",
    "    \"resized_by_width_chara_1.png\",\n",
    "    \"resized_by_height_chara_1.png\",\n",
    "    \"resized_by_area_chara_1.png\"\n",
    "]\n",
    "\n",
    "model = YOLO(\"./yolov8n-face.pt\")\n",
    "for sub_img_name in sub_img_names:\n",
    "    base_img = Image.open(\"img/human_2.jpeg\")\n",
    "    sub_img = Image.open(f\"resized_img/{sub_img_name}\")\n",
    "\n",
    "    results = model.predict(source=\"img/human_2.jpeg\")\n",
    "    h_xywh = results[0].boxes[0].xywh[0]\n",
    "    # (h_x, h_y, h_w, h_h) = results[0].boxes[0].xywh[0]\n",
    "\n",
    "    results = model.predict(source=f\"resized_img/{sub_img_name}\")\n",
    "    c_xywh = results[0].boxes[0].xywh[0]\n",
    "    # (c_x, c_y, c_w, c_h) = results[0].boxes[0].xywh[0]\n",
    "\n",
    "    margin = 50\n",
    "    base_img.paste(sub_img,\n",
    "                    box=(int(h_xywh[0] + h_xywh[2] + margin - c_xywh[0]),\n",
    "                            int(h_xywh[1] + h_xywh[3]/2 - c_xywh[1] - c_xywh[3]/2))\n",
    "                    ,mask=sub_img)\n",
    "    base_img.save(f\"regenerated_img/{sub_img_name}\")\n",
    "\n",
    "# # image paste on case of \"1. adjust to width\"\n",
    "# base_img = Image.open(\"img/human_2.jpeg\")\n",
    "# sub_img = Image.open(\"resized_img/resized_by_area_chara_1.png\")\n",
    "\n",
    "# model = YOLO(\"./yolov8n-face.pt\")\n",
    "# results = model.predict(source=\"img/human_2.jpeg\")\n",
    "# h_xywh = results[0].boxes[0].xywh[0]\n",
    "# results = model.predict(source=\"resized_img/resized_by_area_chara_1.png\")\n",
    "# c_xywh = results[0].boxes[0].xywh[0]\n",
    "\n",
    "# # paste image\n",
    "# margin = 50 * human_box_xywh[2] / chara_box_xywh[2]\n",
    "# base_img.paste(sub_img,\n",
    "#                box=(int(h_xywh[0] + h_xywh[2] + margin - c_xywh[0]),\n",
    "#                 int(h_xywh[1] + h_xywh[3]/2 - c_xywh[1] - c_xywh[3]/2))\n",
    "#                 ,mask=sub_img)\n",
    "# base_img.show()\n",
    "\n",
    "# base_img.save(\"regenerated_img/regenerated_by_weight_chara_1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ea514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(source=\"regenerated_img/resized_by_width_chara_1.png\", save=True, show=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
